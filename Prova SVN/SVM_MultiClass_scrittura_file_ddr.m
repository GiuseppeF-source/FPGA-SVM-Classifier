%dataset https://archive.ics.uci.edu/ml/datasets/Dermatology
clc;
clear;
%fatto confronto con classificationLearner

%% Import Dermatology Dataset

% Script for importing data from the following text file:
%
%    C:\Users\yoxo\Desktop\Giuseppe\Unical\CdL_LM_Tesi\Prova SVN\Dermatology Dataset\dermatology.data
%
% To extend the code to different selected data or a different text file,
% generate a function instead of a script.

% Auto-generated by MATLAB on 2022/01/25 10:17:16
filename = 'C:\Users\yoxo\Desktop\Giuseppe\Unical\CdL_LM_Tesi\Prova SVN\Dermatology Dataset\dermatology.data';
delimiter = ',';


%   column1: double (%f)
%	column2: double (%f)
%   column3: double (%f)
%	column4: double (%f)
%   column5: double (%f)
%	column6: double (%f)
%   column7: double (%f)
%	column8: double (%f)
%   column9: double (%f)
%	column10: double (%f)
%   column11: double (%f)
%	column12: double (%f)
%   column13: double (%f)
%	column14: double (%f)
%   column15: double (%f)
%	column16: double (%f)
%   column17: double (%f)
%	column18: double (%f)
%   column19: double (%f)
%	column20: double (%f)
%   column21: double (%f)
%	column22: double (%f)
%   column23: double (%f)
%	column24: double (%f)
%   column25: double (%f)
%	column26: double (%f)
%   column27: double (%f)
%	column28: double (%f)
%   column29: double (%f)
%	column30: double (%f)
%   column31: double (%f)
%	column32: double (%f)
%   column33: double (%f)
%	column34: double (%f)
%   column35: double (%f)
% For more information, see the TEXTSCAN documentation.
formatSpec = '%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%[^\n\r]';
fileID = fopen(filename,'r');
% This call is based on the structure of the file used to generate this
% code. If an error occurs for a different file, try regenerating the code
% from the Import Tool.
dataArray = textscan(fileID, formatSpec, 'Delimiter', delimiter, 'TextType', 'string',  'ReturnOnError', false);
fclose(fileID);

% No unimportable data rules were applied during the import, so no post
% processing code is included. To generate code which works for
% unimportable data, select unimportable cells in a file and regenerate the
% script.
dermatology = table(dataArray{1:end-1}, 'VariableNames', {'erythema','scaling','definite_borders','itching','koebner_phenomenon','polygonal_papules','follicular_papules','oral_mucosal_involvement','knee_and_elbow_involvement','scalp_involvement','family_history','melanin_incontinence','eosinophils_in_the_infiltrate','PNL_infiltrate','fibrosis_of_the_papillary_dermis','exocytosis','acanthosis','hyperkeratosis','parakeratosis','clubbing_of_the_rete_ridges','elongation_of_the_rete_ridges','thinning_of_the_suprapapillary_epidermis','spongiform_pustule','munro_microabcess','focal_hypergranulosis','disappearance_of_the_granular_layer','vacuolisation_and_damage_of_basal_layer','spongiosis','saw_tooth_appearance_of_retes','follicular_horn_plug','perifollicular_parakeratosis','inflammatory_monoluclear_inflitrate','band_like_infiltrate','Age','Class'});
clearvars filename delimiter formatSpec fileID dataArray ans;

%% Separazione Attribute-Class
Attribute = dermatology(:,1:34);
Class = dermatology(:,35);

%% Train SVM w ECOC/OvO
rng(1); % For reproducibility
t = templateSVM('Standardize',false,'BoxConstraint',1,'KernelScale','auto','SaveSupportVectors',true,'KernelFunction','linear');
Model_SVM = fitcecoc(Attribute,Class,'Coding','onevsone','Learners',t);

%% Cross Validation and Accuracy 
rng('default');
CV_Model_SVM = crossval(Model_SVM); % default a 10fold
error = kfoldLoss(CV_Model_SVM);
Accuracy = ( 1 - error )*100;
error_individual = kfoldLoss(CV_Model_SVM,'Mode','individual');
Accuracy_individual = ( 1 - error_individual )*100;

% for fractional = 0:8
%%    Fixed-Point
Attribute_type                = numerictype('Signed',1,'WordLength', 8,'FractionLength', 0 );
Alpha_type                    = numerictype('Signed',0,'WordLength',16,'FractionLength',15 );
Bias_type                     = numerictype('Signed',1,'WordLength', 7,'FractionLength',4  );  % miglior Accuracy con 4 bit fract
Kernel_Scale_type             = numerictype('Signed',1,'WordLength',16,'FractionLength',10 );
Score_type                    = numerictype('Signed',1,'WordLength',17,'FractionLength',13 ); % era - 10
Kernel_Scale_inv_quadro_type  = numerictype('Signed',1,'WordLength',12,'FractionLength',10 ); % miglior Accuracy con 10 bit fract
Acc_SV_x_Alpha_x_SVLabel_type = numerictype('Signed',1,'WordLength',12,'FractionLength',5  ); % miglior Accuracy con 5 bit fract

%% Testing partition 
Alpha_tot = zeros(100,15,10); % variabile che raccoglie tutti gli aplha per determinare il fixed point
Support_vectors_tot = zeros(1,15,10);

for partition = 1:1
    
    testInds = test(CV_Model_SVM.Partition,partition);
    Attribute_Test = Attribute(testInds,:);
    Class_Test = Class(testInds,:);
    % Classificazione
    [Class_Predict]= predict(CV_Model_SVM.Trained{partition},Attribute_Test); 

       % apertura file in scrittura e assegnazione ID
%        percorso_partizione = sprintf("C:\\Users\\yoxo\\Desktop\\Giuseppe\\Unical\\CdL_LM_Tesi\\Dati_Classifier_bin\\Coefficienti\\Partizione_%s\\",string(partition));
%        f_Bias_id = fopen(percorso_partizione+"Bias.dat",'wt');
%        f_Kernel_Scale_id = fopen(percorso_partizione+"Kernel_Scale.dat",'wt');
%        f_Acc_SVxAlphaxSVLabel_id = fopen(percorso_partizione+"Acc_SVxAlphaxSVLabel.dat",'wt');
%        f_Attribute_Test_id = fopen(percorso_partizione+"Attribute_Test.dat","wt");
       
    
    %% Costruzione manuale del predict

    Attribute_Test = table2array(Attribute_Test); %conv da table a double
    predict_manual_voting = zeros(length(Attribute_Test),1);
    predict_manual_decoding_loss = zeros(length(Attribute_Test),1);
    
    for indx_Attribute_Test = 1:length(Attribute_Test)

        OUT_SVM = zeros(length(CV_Model_SVM.Trained{partition}.BinaryLearners),1);
        score   = zeros(length(CV_Model_SVM.Trained{partition}.BinaryLearners),1);
        y_prova = zeros(length(CV_Model_SVM.Trained{partition}.BinaryLearners),1);
        
        % Processamento per tutti ed n SVM
        for n = 1:length(CV_Model_SVM.Trained{partition}.BinaryLearners)
            Bias_fi = fi ( CV_Model_SVM.Trained{partition}.BinaryLearners{n, 1}.Bias, Bias_type);
            Bias = double( Bias_fi );
            SupportVectors = CV_Model_SVM.Trained{partition}.BinaryLearners{n, 1}.SupportVectors;
            SupportVectorLabels = CV_Model_SVM.Trained{partition}.BinaryLearners{n, 1}.SupportVectorLabels;
            %Alpha = double( fi ( CV_Model_SVM.Trained{partition}.BinaryLearners{n, 1}.Alpha, Alpha_type  ));
            Alpha_not_fi = CV_Model_SVM.Trained{partition}.BinaryLearners{n, 1}.Alpha;
            %Mu = CV_Model_SVM.Trained{1, 1}.BinaryLearners{n, 1}.Mu;
            %Sigma = CV_Model_SVM.Trained{1, 1}.BinaryLearners{n, 1}.Sigma;
            Kernel_Scale =  CV_Model_SVM.Trained{partition}.BinaryLearners{n, 1}.KernelParameters.Scale ;
            Kernel_Scale_inv_quadr_fi = fi ( (Kernel_Scale^-2) ,Kernel_Scale_inv_quadro_type );
            Kernel_Scale_inv_quadr = double( Kernel_Scale_inv_quadr_fi ) ;
            % Standardize data x* = (x-mu)/sigma
            %Attribute_Test_std = (Attribute_Test - Mu)./Sigma;

            % classificazione per singolo attributo
            %numRows = length(Alpha_not_fi);
            
            %---------- Prova Soluzione Pre-computata----------------------
            SV_x_Alpha_x_SVLabel = (Alpha_not_fi.*SupportVectors).*SupportVectorLabels;
            Acc_SV_x_Alpha_x_SVLabel_fi = fi(...
                                             sum(SV_x_Alpha_x_SVLabel) , Acc_SV_x_Alpha_x_SVLabel_type );
            Acc_SV_x_Alpha_x_SVLabel = double( Acc_SV_x_Alpha_x_SVLabel_fi ) ;
            y_prova = double(...
                       fi(...
                            dot((Attribute_Test(indx_Attribute_Test,:)),Acc_SV_x_Alpha_x_SVLabel),1,25,4) ) ...
                                          *Kernel_Scale_inv_quadr + Bias;
%             y_prova = dot((Attribute_Test(indx_Attribute_Test,:)),Acc_SV_x_Alpha_x_SVLabel) ...
%                                           *Kernel_Scale_inv_quadr + Bias;
                                           
            %------------ Fine prova --------------------------------------
            
%             y = Bias;
%             for i = 1:numRows
%                 kernel = Kernel_Scale_inv_quadr*((Attribute_Test(indx_Attribute_Test,:)))*(SupportVectors(i,:)'); % lineare
%                % kernel = exp((-(norm(Attribute_Test(indx_Attribute_Test,:) - SupportVectors(i,:)))^2)/(Kernel_Scale^2)); % gaussian 
%                 y = y + kernel*(Alpha(i,1)*SupportVectorLabels(i,1));
%             end
            
  
            %score(n,1) = double( fi (y, Score_type ) ); 
            score(n,1) = y_prova;
            OUT_SVM(n,1) = sign(y_prova);
            
            
            % per capire max e min dei coeff. e attr.
            
            %             Bias_tot(n,1,partition) = Bias;
            %             Alpha_tot(1:numel(Alpha),n,partition) = Alpha;
            %             Kernel_Scale_tot(n,1,partition) = (Kernel_Scale^-2);
            %             Support_vectors_tot(1,n,partition) = max(max(SupportVectors));
            %             Support_vectors_size(1,n,partition) = size(SupportVectors,1);
            %             Score_tot(n,indx_Attribute_Test,partition) = y;
            %             Acc_SV_x_Alpha_x_SVLabel_tot(1:34,n,partition) = Acc_SV_x_Alpha_x_SVLabel;
            
            
            
%             % Salvataggio su File 
%             if (indx_Attribute_Test == 1) % per farlo una sola volta
%                 fprintf(f_Bias_id,"%s\n", bin( Bias_fi )  );
%                 
%                 fprintf(f_Kernel_Scale_id,"%s\n", bin( Kernel_Scale_inv_quadr_fi  ) );
%                 
%                 string_vect_pre_computed = bin( Acc_SV_x_Alpha_x_SVLabel_fi );
%                 
%                 for s = 0:1:33
%                     % con inizio e fine prendo le giuste porzioni della
%                     % stringa string_vect_pre_computed, escludendo gli
%                     % spazi, in modo da poterli affiancare. 
%                     % gli spazi occupano 3 posizioni colonna.
%                     inizio = s*15+1;
%                     fine = s*15+12;
%                     fprintf(f_Acc_SVxAlphaxSVLabel_id,"%s",string_vect_pre_computed(1,inizio:fine) );
%                 end
%                 fprintf(f_Acc_SVxAlphaxSVLabel_id,"\n");
%             end
%             
%             % Salvataggio Attributi per il Test 
%               % formare unica word da 8bit * 34 Attributi
%             if ( n == 1 ) % attributi uguali per tutte ed n le SVM => prelevo una sola volta
%             string_Attribute_Test = bin (...
%                                     fi ( ...
%                                     (Attribute_Test(indx_Attribute_Test,:)),Attribute_type));
%                 for j = 0:1:33
%                     inizio = j*11+1; % 11 = 8bit Attr. + 3 spazi
%                     fine = j*11+8;
%                     fprintf(f_Attribute_Test_id,"%s",string_Attribute_Test(1,inizio:fine) );
%                 end
%                 fprintf(f_Attribute_Test_id,"\n");
%             end


            
        end
%         fclose('all');


        % Voting - assegno voto comparando:
        %   l'output di ogni SVM con la rispettiva colonna della Coding Matrix

        vote = zeros(6,1);

        for j = 1:length(OUT_SVM)
            if OUT_SVM(j,1) == 1
                ind_scorr_riga = 1;
                while (CV_Model_SVM.Trained{1, 1}.CodingMatrix(ind_scorr_riga,j) ~= 1)
                    ind_scorr_riga = ind_scorr_riga + 1;
                end
                vote(ind_scorr_riga,1) =  vote(ind_scorr_riga,1) + 1;
            elseif  OUT_SVM(j,1) == -1
                ind_scorr_riga = 1;
                while (CV_Model_SVM.Trained{1, 1}.CodingMatrix(ind_scorr_riga,j) ~= -1)
                    ind_scorr_riga = ind_scorr_riga + 1;
                end
                vote(ind_scorr_riga,1) =  vote(ind_scorr_riga,1) + 1;
            end
        end

        [max,index_max] = max(vote);
        predict_manual_voting(indx_Attribute_Test) = index_max;
        clearvars max index_max; 


        % Loss-weighted decoding manual - hinge function
         weight_k = sum( abs(CV_Model_SVM.Trained{partition}.CodingMatrix) ,2);
         average_loss_svm = zeros(1,6);
         for k = 1:numel(weight_k)
             loss_fun = (1 - (CV_Model_SVM.Trained{partition}.CodingMatrix(k,:).*score(:)'))./2;

             for j= 1:numel(loss_fun)
                 if loss_fun(j) <= 0
                     loss_fun(j) = 0;
                 end
             end
             average_loss_svm(k) =  sum((abs(CV_Model_SVM.Trained{partition}.CodingMatrix(k,:)).*loss_fun))/weight_k(k);
         end
         [min,index_min] = min(average_loss_svm);
         predict_manual_decoding_loss(indx_Attribute_Test) = index_min;
         clearvars min index_min;

    end

    %% Confronto risultati manuali con predict ed originali 

    orig_vs_predict_vs_voting_vs_decoding = [Class_Test table(Class_Predict) table(predict_manual_voting) table(predict_manual_decoding_loss)];
    orig_vs_predict_vs_manual.Properties.VariableNames = {'Original' 'Predict' 'Manual_Voting' 'Loss-weighted decoding'};

    ris_predict = zeros(numel(Class_Test),1);
    ris_predict_manual_voting = zeros(numel(Class_Test),1);
    ris_predict_manual_decoding_loss = zeros(numel(Class_Test),1);
    for i = 1:numel(Class_Test)
          ris_predict(i) = (table2array(Class_Test(i,1)) == Class_Predict(i,1));  
          ris_predict_manual_voting(i) = (table2array(Class_Test(i,1)) == predict_manual_voting(i,1));
          ris_predict_manual_decoding_loss(i) = (table2array(Class_Test(i,1)) == predict_manual_decoding_loss(i,1));
    end
    Prob_predict(partition) = sum(ris_predict)*100/numel(ris_predict); %#ok<SAGROW>
    Prob_predict_manual_voting(partition) = sum(ris_predict_manual_voting)*100/numel(ris_predict_manual_voting); %#ok<SAGROW>
    Prob_predict_manual_decoding_loss(partition) = sum(ris_predict_manual_decoding_loss)*100/numel(ris_predict_manual_decoding_loss); %#ok<SAGROW>
end

comp_prob_all_method = ["Predict","Voting","Decoding_Loss";...
    Prob_predict',Prob_predict_manual_voting',Prob_predict_manual_decoding_loss'];
comp_mean_all_method = ["Mean Predict","Mean Voting","Mean Decoding_Loss";...
    mean(Prob_predict),mean(Prob_predict_manual_voting),mean(Prob_predict_manual_decoding_loss)];


%Accuratezza dipendente dalla parte frazionale 
%     Accuracy_fractional_dependent(9 - fractional,:) = [mean(Prob_predict),mean(Prob_predict_manual_voting),mean(Prob_predict_manual_decoding_loss)];
% end
% 
% figure;
% title("Accuracy dependent of fractional part");
% plot(1:9,Accuracy_fractional_dependent(:,1),'-.', ...
%      1:9,Accuracy_fractional_dependent(:,2),':', ...
%      1:9,Accuracy_fractional_dependent(:,3),'--'   );
% axis([1 9 95.9 100]);
% xlabel("Fractional part of Pre-Comp Sum(SV*Alpha*SVLabel)");
% ylabel('Accuracy');
% legend("Predict of MATLAB","Manual Voting","Manual Decoding Loss");